{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c83eb452",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/torch/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "from scipy.spatial.distance import cosine\n",
    "import pickle\n",
    "from tqdm import tqdm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93841597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 100 examples. Sample:\n",
      "{'sentence1': 'Here, looking for agents that could specifically kill KRAS mutant cells, they found that knockdown of GATA2 was synthetically lethal with KRAS mutation', 'sentence2': 'Not surprisingly, GATA2 knockdown in KRAS mutant cells resulted in a striking reduction of active GTP-bound RHO proteins, including the downstream ROCK kinase', 'score': 2.200000047683716} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "#dataset = load_dataset(\"sentence-transformers/stsb\", split=\"train\")\n",
    "dataset = load_dataset(\"tabilab/biosses\", split=\"train\")\n",
    "print(f\"Loaded {len(dataset)} examples. Sample:\")\n",
    "print(dataset[0], \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0750870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing dimension  64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<All keys matched successfully>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting embedding and measuring similarity ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:54<00:00,  1.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing dimension  256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<All keys matched successfully>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting embedding and measuring similarity ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:47<00:00,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing dimension  512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<All keys matched successfully>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting embedding and measuring similarity ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:47<00:00,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing dimension  768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<All keys matched successfully>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting embedding and measuring similarity ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:47<00:00,  1.08s/it]\n"
     ]
    }
   ],
   "source": [
    "# Generate embeddings for the first few sentence pairs (do not run without need, save results, costs money)\n",
    "model_name = 'nomic-embed-text-v1.5'\n",
    "dims = [64, 256, 512, 768]\n",
    "\n",
    "for dim in dims:\n",
    "    print('Doing dimension ', dim)\n",
    "    file_to_save = 'biosses/nomic_text-'+model_name+'_'+str(dim)+'.pickle'\n",
    "    embeddings = pd.DataFrame()\n",
    "    sentence1 = []\n",
    "    sentence2 = []\n",
    "    embedding1 = []\n",
    "    embedding2 = []\n",
    "    cosine_similarity = []\n",
    "    human_score = []\n",
    "\n",
    "    model = SentenceTransformer(\"nomic-ai/\"+model_name, trust_remote_code=True, truncate_dim=64)\n",
    "\n",
    "    print('Extracting embedding and measuring similarity ...')\n",
    "    time.sleep(1)\n",
    "    for idx in tqdm(range(len(dataset))):\n",
    "        first_sentence = dataset[idx][\"sentence1\"]\n",
    "        emb1 = response = list(model.encode(first_sentence))\n",
    "        sentence1.append(\n",
    "            first_sentence\n",
    "        )\n",
    "        embedding1.append(\n",
    "            emb1\n",
    "        )\n",
    "        #############################\n",
    "        second_sentence = dataset[idx][\"sentence2\"]\n",
    "        emb2 = list(model.encode(second_sentence))\n",
    "        sentence2.append(\n",
    "            second_sentence\n",
    "        )\n",
    "        embedding2.append(\n",
    "            emb2\n",
    "        )\n",
    "        \n",
    "        ############################\n",
    "        cosine_similarity.append(\n",
    "            1 - cosine(emb1, emb2)\n",
    "        )\n",
    "        human_score.append(\n",
    "            dataset[idx][\"score\"]/4.0\n",
    "        )\n",
    "        \n",
    "        time.sleep(1)  # respect rate limits!\n",
    "\n",
    "    embeddings['Sentence 1'] = sentence1\n",
    "    embeddings['Sentence 2'] = sentence2\n",
    "    embeddings['Embedding of Sentence 1'] = embedding1\n",
    "    embeddings['Embedding of Sentence 2'] = embedding2\n",
    "    embeddings['Cosine similarity'] = cosine_similarity\n",
    "    embeddings['Human score'] = human_score\n",
    "\n",
    "    with open(file_to_save, 'wb') as f:\n",
    "        pickle.dump(embeddings, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "660b6c03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence 1</th>\n",
       "      <th>Sentence 2</th>\n",
       "      <th>Embedding of Sentence 1</th>\n",
       "      <th>Embedding of Sentence 2</th>\n",
       "      <th>Cosine similarity</th>\n",
       "      <th>Human score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Here, looking for agents that could specifical...</td>\n",
       "      <td>Not surprisingly, GATA2 knockdown in KRAS muta...</td>\n",
       "      <td>[0.37600115, -0.16444215, -3.428607, 1.0291133...</td>\n",
       "      <td>[0.41314304, -0.003164128, -2.8305767, 0.55561...</td>\n",
       "      <td>0.858913</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MLL-FKBP and MLL-AF9 transformed cells showed ...</td>\n",
       "      <td>Regardless of the mechanism for transcriptiona...</td>\n",
       "      <td>[0.3319264, 0.1859387, -3.2266126, 0.57614785,...</td>\n",
       "      <td>[-0.12157992, 0.700806, -3.0858023, 0.83130765...</td>\n",
       "      <td>0.914254</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The oncogenic activity of mutant Kras appears ...</td>\n",
       "      <td>Oncogenic KRAS mutations are common in cancer.</td>\n",
       "      <td>[0.1695996, -0.41325438, -3.1154187, 0.7725454...</td>\n",
       "      <td>[0.6242161, -0.060434245, -3.234395, 0.7518816...</td>\n",
       "      <td>0.871847</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Consequently miRNAs have been demonstrated to ...</td>\n",
       "      <td>Given the extensive involvement of miRNA in ph...</td>\n",
       "      <td>[-0.27360806, 0.0042789746, -3.075625, -0.1715...</td>\n",
       "      <td>[0.36149248, 0.41634881, -2.6628473, 0.4822917...</td>\n",
       "      <td>0.904348</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>We then sought to reassess the regulation of m...</td>\n",
       "      <td>Importantly, our reassessment revealed that th...</td>\n",
       "      <td>[-0.5231466, 0.36688644, -3.3939989, -0.380803...</td>\n",
       "      <td>[-0.4272349, 0.38933787, -2.6761675, -0.285906...</td>\n",
       "      <td>0.834761</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Sentence 1  \\\n",
       "0  Here, looking for agents that could specifical...   \n",
       "1  MLL-FKBP and MLL-AF9 transformed cells showed ...   \n",
       "2  The oncogenic activity of mutant Kras appears ...   \n",
       "3  Consequently miRNAs have been demonstrated to ...   \n",
       "4  We then sought to reassess the regulation of m...   \n",
       "\n",
       "                                          Sentence 2  \\\n",
       "0  Not surprisingly, GATA2 knockdown in KRAS muta...   \n",
       "1  Regardless of the mechanism for transcriptiona...   \n",
       "2     Oncogenic KRAS mutations are common in cancer.   \n",
       "3  Given the extensive involvement of miRNA in ph...   \n",
       "4  Importantly, our reassessment revealed that th...   \n",
       "\n",
       "                             Embedding of Sentence 1  \\\n",
       "0  [0.37600115, -0.16444215, -3.428607, 1.0291133...   \n",
       "1  [0.3319264, 0.1859387, -3.2266126, 0.57614785,...   \n",
       "2  [0.1695996, -0.41325438, -3.1154187, 0.7725454...   \n",
       "3  [-0.27360806, 0.0042789746, -3.075625, -0.1715...   \n",
       "4  [-0.5231466, 0.36688644, -3.3939989, -0.380803...   \n",
       "\n",
       "                             Embedding of Sentence 2  Cosine similarity  \\\n",
       "0  [0.41314304, -0.003164128, -2.8305767, 0.55561...           0.858913   \n",
       "1  [-0.12157992, 0.700806, -3.0858023, 0.83130765...           0.914254   \n",
       "2  [0.6242161, -0.060434245, -3.234395, 0.7518816...           0.871847   \n",
       "3  [0.36149248, 0.41634881, -2.6628473, 0.4822917...           0.904348   \n",
       "4  [-0.4272349, 0.38933787, -2.6761675, -0.285906...           0.834761   \n",
       "\n",
       "   Human score  \n",
       "0         0.55  \n",
       "1         0.80  \n",
       "2         0.50  \n",
       "3         0.70  \n",
       "4         0.60  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05eda8a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
