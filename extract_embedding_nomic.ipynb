{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c83eb452",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/torch/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "from scipy.spatial.distance import cosine\n",
    "import pickle\n",
    "from tqdm import tqdm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93841597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 5749 examples. Sample:\n",
      "{'sentence1': 'A plane is taking off.', 'sentence2': 'An air plane is taking off.', 'score': 1.0} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "dataset = load_dataset(\"sentence-transformers/stsb\", split=\"train\")\n",
    "print(f\"Loaded {len(dataset)} examples. Sample:\")\n",
    "print(dataset[0], \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0750870",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<All keys matched successfully>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting embedding and measuring similarity ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5749/5749 [1:43:02<00:00,  1.08s/it]\n"
     ]
    }
   ],
   "source": [
    "# Generate embeddings for the first few sentence pairs (do not run without need, save results, costs money)\n",
    "model_name = 'nomic-embed-text-v1'\n",
    "file_to_save = 'nomic_text-'+model_name+'.pickle'\n",
    "embeddings = pd.DataFrame()\n",
    "sentence1 = []\n",
    "sentence2 = []\n",
    "embedding1 = []\n",
    "embedding2 = []\n",
    "cosine_similarity = []\n",
    "human_score = []\n",
    "\n",
    "model = SentenceTransformer(\"nomic-ai/\"+model_name, trust_remote_code=True)\n",
    "\n",
    "print('Extracting embedding and measuring similarity ...')\n",
    "time.sleep(1)\n",
    "for idx in tqdm(range(len(dataset))):\n",
    "    first_sentence = dataset[idx][\"sentence1\"]\n",
    "    emb1 = response = list(model.encode(first_sentence))\n",
    "    sentence1.append(\n",
    "        first_sentence\n",
    "    )\n",
    "    embedding1.append(\n",
    "        emb1\n",
    "    )\n",
    "    #############################\n",
    "    second_sentence = dataset[idx][\"sentence2\"]\n",
    "    emb2 = list(model.encode(second_sentence))\n",
    "    sentence2.append(\n",
    "        second_sentence\n",
    "    )\n",
    "    embedding2.append(\n",
    "        emb2\n",
    "    )\n",
    "    \n",
    "    ############################\n",
    "    cosine_similarity.append(\n",
    "        1 - cosine(emb1, emb2)\n",
    "    )\n",
    "    human_score.append(\n",
    "        dataset[idx][\"score\"]\n",
    "    )\n",
    "    \n",
    "    time.sleep(1)  # respect rate limits!\n",
    "\n",
    "embeddings['Sentence 1'] = sentence1\n",
    "embeddings['Sentence 2'] = sentence2\n",
    "embeddings['Embedding of Sentence 1'] = embedding1\n",
    "embeddings['Embedding of Sentence 2'] = embedding2\n",
    "embeddings['Cosine similarity'] = cosine_similarity\n",
    "embeddings['Human score'] = human_score\n",
    "\n",
    "with open(file_to_save, 'wb') as f:\n",
    "    pickle.dump(embeddings, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "660b6c03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence 1</th>\n",
       "      <th>Sentence 2</th>\n",
       "      <th>Embedding of Sentence 1</th>\n",
       "      <th>Embedding of Sentence 2</th>\n",
       "      <th>Cosine similarity</th>\n",
       "      <th>Human score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A plane is taking off.</td>\n",
       "      <td>An air plane is taking off.</td>\n",
       "      <td>[-0.026247814297676086, 0.01684456691145897, -...</td>\n",
       "      <td>[-0.035567473620176315, -0.001996719976887107,...</td>\n",
       "      <td>0.889733</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A man is playing a large flute.</td>\n",
       "      <td>A man is playing a flute.</td>\n",
       "      <td>[0.01073455810546875, -0.054696112871170044, -...</td>\n",
       "      <td>[0.010396339930593967, -0.023768354207277298, ...</td>\n",
       "      <td>0.732201</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A man is spreading shreded cheese on a pizza.</td>\n",
       "      <td>A man is spreading shredded cheese on an uncoo...</td>\n",
       "      <td>[-0.012448686175048351, 0.029658401384949684, ...</td>\n",
       "      <td>[0.00020476203644648194, 0.004532653372734785,...</td>\n",
       "      <td>0.913542</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Three men are playing chess.</td>\n",
       "      <td>Two men are playing chess.</td>\n",
       "      <td>[0.02218366600573063, 0.014727897942066193, -0...</td>\n",
       "      <td>[0.00860250648111105, -0.0020768065005540848, ...</td>\n",
       "      <td>0.727974</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A man is playing the cello.</td>\n",
       "      <td>A man seated is playing the cello.</td>\n",
       "      <td>[0.003227482782676816, -0.0025188112631440163,...</td>\n",
       "      <td>[-0.003892626380547881, -0.007955207489430904,...</td>\n",
       "      <td>0.788158</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Sentence 1  \\\n",
       "0                         A plane is taking off.   \n",
       "1                A man is playing a large flute.   \n",
       "2  A man is spreading shreded cheese on a pizza.   \n",
       "3                   Three men are playing chess.   \n",
       "4                    A man is playing the cello.   \n",
       "\n",
       "                                          Sentence 2  \\\n",
       "0                        An air plane is taking off.   \n",
       "1                          A man is playing a flute.   \n",
       "2  A man is spreading shredded cheese on an uncoo...   \n",
       "3                         Two men are playing chess.   \n",
       "4                 A man seated is playing the cello.   \n",
       "\n",
       "                             Embedding of Sentence 1  \\\n",
       "0  [-0.026247814297676086, 0.01684456691145897, -...   \n",
       "1  [0.01073455810546875, -0.054696112871170044, -...   \n",
       "2  [-0.012448686175048351, 0.029658401384949684, ...   \n",
       "3  [0.02218366600573063, 0.014727897942066193, -0...   \n",
       "4  [0.003227482782676816, -0.0025188112631440163,...   \n",
       "\n",
       "                             Embedding of Sentence 2  Cosine similarity  \\\n",
       "0  [-0.035567473620176315, -0.001996719976887107,...           0.889733   \n",
       "1  [0.010396339930593967, -0.023768354207277298, ...           0.732201   \n",
       "2  [0.00020476203644648194, 0.004532653372734785,...           0.913542   \n",
       "3  [0.00860250648111105, -0.0020768065005540848, ...           0.727974   \n",
       "4  [-0.003892626380547881, -0.007955207489430904,...           0.788158   \n",
       "\n",
       "   Human score  \n",
       "0         1.00  \n",
       "1         0.76  \n",
       "2         0.76  \n",
       "3         0.52  \n",
       "4         0.85  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef57ca46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9338326096981154,\n",
       " 0.8674470444752889,\n",
       " 0.8910569082430774,\n",
       " 0.8371824026107788,\n",
       " 0.8662249108023918]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05eda8a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
