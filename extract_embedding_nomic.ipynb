{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c83eb452",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/torch/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "from scipy.spatial.distance import cosine\n",
    "import pickle\n",
    "from tqdm import tqdm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93841597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 5749 examples. Sample:\n",
      "{'sentence1': 'A plane is taking off.', 'sentence2': 'An air plane is taking off.', 'score': 1.0} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "dataset = load_dataset(\"sentence-transformers/stsb\", split=\"train\")\n",
    "#dataset = load_dataset(\"tabilab/biosses\", split=\"train\")\n",
    "print(f\"Loaded {len(dataset)} examples. Sample:\")\n",
    "print(dataset[0], \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0750870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing dimension  768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jd/.cache/huggingface/modules/transformers_modules/nomic-ai/nomic-bert-2048/7710840340a098cfb869c4f65e87cf2b1b70caca/modeling_hf_nomic_bert.py:1634: UserWarning: Install Nomic's megablocks fork for better speed: `pip install git+https://github.com/nomic-ai/megablocks.git`\n",
      "  warnings.warn(\"Install Nomic's megablocks fork for better speed: \" +\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting embedding and measuring similarity ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5749/5749 [2:06:20<00:00,  1.32s/it]  \n"
     ]
    }
   ],
   "source": [
    "# Generate embeddings for the first few sentence pairs (do not run without need, save results, costs money)\n",
    "model_name = 'nomic-embed-text-v2-moe'#'nomic-embed-text-v1.5'\n",
    "dims = [768]#[64, 256, 512, 768]\n",
    "\n",
    "for dim in dims:\n",
    "    print('Doing dimension ', dim)\n",
    "    file_to_save = 'stsb/nomic_text-'+model_name+'_'+str(dim)+'.pickle'\n",
    "    embeddings = pd.DataFrame()\n",
    "    sentence1 = []\n",
    "    sentence2 = []\n",
    "    embedding1 = []\n",
    "    embedding2 = []\n",
    "    cosine_similarity = []\n",
    "    human_score = []\n",
    "\n",
    "    model = SentenceTransformer(\"nomic-ai/\"+model_name, trust_remote_code=True, truncate_dim=64)\n",
    "\n",
    "    print('Extracting embedding and measuring similarity ...')\n",
    "    time.sleep(1)\n",
    "    for idx in tqdm(range(len(dataset))):\n",
    "        first_sentence = dataset[idx][\"sentence1\"]\n",
    "        emb1 = response = list(model.encode(first_sentence))\n",
    "        sentence1.append(\n",
    "            first_sentence\n",
    "        )\n",
    "        embedding1.append(\n",
    "            emb1\n",
    "        )\n",
    "        #############################\n",
    "        second_sentence = dataset[idx][\"sentence2\"]\n",
    "        emb2 = list(model.encode(second_sentence))\n",
    "        sentence2.append(\n",
    "            second_sentence\n",
    "        )\n",
    "        embedding2.append(\n",
    "            emb2\n",
    "        )\n",
    "        \n",
    "        ############################\n",
    "        cosine_similarity.append(\n",
    "            1 - cosine(emb1, emb2)\n",
    "        )\n",
    "        human_score.append(\n",
    "            dataset[idx][\"score\"]#/4.0 #comment out this depending on the data\n",
    "        )\n",
    "        \n",
    "        time.sleep(1)  # respect rate limits!\n",
    "\n",
    "    embeddings['Sentence 1'] = sentence1\n",
    "    embeddings['Sentence 2'] = sentence2\n",
    "    embeddings['Embedding of Sentence 1'] = embedding1\n",
    "    embeddings['Embedding of Sentence 2'] = embedding2\n",
    "    embeddings['Cosine similarity'] = cosine_similarity\n",
    "    embeddings['Human score'] = human_score\n",
    "\n",
    "    with open(file_to_save, 'wb') as f:\n",
    "        pickle.dump(embeddings, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "660b6c03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence 1</th>\n",
       "      <th>Sentence 2</th>\n",
       "      <th>Embedding of Sentence 1</th>\n",
       "      <th>Embedding of Sentence 2</th>\n",
       "      <th>Cosine similarity</th>\n",
       "      <th>Human score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A plane is taking off.</td>\n",
       "      <td>An air plane is taking off.</td>\n",
       "      <td>[0.015153886, 0.041404974, -0.014125247, 0.016...</td>\n",
       "      <td>[0.010745221, 0.05729635, -0.016948922, 0.0269...</td>\n",
       "      <td>0.966485</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A man is playing a large flute.</td>\n",
       "      <td>A man is playing a flute.</td>\n",
       "      <td>[0.0024366875, 0.032083724, 0.018080892, -0.03...</td>\n",
       "      <td>[0.014941305, 0.031600654, -0.010353177, -0.03...</td>\n",
       "      <td>0.919278</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A man is spreading shreded cheese on a pizza.</td>\n",
       "      <td>A man is spreading shredded cheese on an uncoo...</td>\n",
       "      <td>[0.03733847, 0.00078736147, 0.0005427449, 0.03...</td>\n",
       "      <td>[0.0301026, 0.0054820334, -0.009974424, 0.0288...</td>\n",
       "      <td>0.951363</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Three men are playing chess.</td>\n",
       "      <td>Two men are playing chess.</td>\n",
       "      <td>[0.06387799, -0.010154583, 0.000906593, 0.0075...</td>\n",
       "      <td>[0.082604, -0.025732871, -0.0040285327, -0.009...</td>\n",
       "      <td>0.931828</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A man is playing the cello.</td>\n",
       "      <td>A man seated is playing the cello.</td>\n",
       "      <td>[0.01687711, -0.008224646, 0.0040950323, -0.00...</td>\n",
       "      <td>[0.027671488, 0.012839296, 0.017273515, 0.0058...</td>\n",
       "      <td>0.938240</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Sentence 1  \\\n",
       "0                         A plane is taking off.   \n",
       "1                A man is playing a large flute.   \n",
       "2  A man is spreading shreded cheese on a pizza.   \n",
       "3                   Three men are playing chess.   \n",
       "4                    A man is playing the cello.   \n",
       "\n",
       "                                          Sentence 2  \\\n",
       "0                        An air plane is taking off.   \n",
       "1                          A man is playing a flute.   \n",
       "2  A man is spreading shredded cheese on an uncoo...   \n",
       "3                         Two men are playing chess.   \n",
       "4                 A man seated is playing the cello.   \n",
       "\n",
       "                             Embedding of Sentence 1  \\\n",
       "0  [0.015153886, 0.041404974, -0.014125247, 0.016...   \n",
       "1  [0.0024366875, 0.032083724, 0.018080892, -0.03...   \n",
       "2  [0.03733847, 0.00078736147, 0.0005427449, 0.03...   \n",
       "3  [0.06387799, -0.010154583, 0.000906593, 0.0075...   \n",
       "4  [0.01687711, -0.008224646, 0.0040950323, -0.00...   \n",
       "\n",
       "                             Embedding of Sentence 2  Cosine similarity  \\\n",
       "0  [0.010745221, 0.05729635, -0.016948922, 0.0269...           0.966485   \n",
       "1  [0.014941305, 0.031600654, -0.010353177, -0.03...           0.919278   \n",
       "2  [0.0301026, 0.0054820334, -0.009974424, 0.0288...           0.951363   \n",
       "3  [0.082604, -0.025732871, -0.0040285327, -0.009...           0.931828   \n",
       "4  [0.027671488, 0.012839296, 0.017273515, 0.0058...           0.938240   \n",
       "\n",
       "   Human score  \n",
       "0         1.00  \n",
       "1         0.76  \n",
       "2         0.76  \n",
       "3         0.52  \n",
       "4         0.85  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05eda8a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
