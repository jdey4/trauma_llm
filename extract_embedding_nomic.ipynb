{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c83eb452",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/torch/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "from scipy.spatial.distance import cosine\n",
    "import pickle\n",
    "from tqdm import tqdm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "620e9612",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_excel('/Users/jd/trauma_llm/trauma_data/embedding_responses_jan28.xlsx', sheet_name=\"NON-EXPERT\")\n",
    "\n",
    "total_response = 5\n",
    "\n",
    "res = dataset['Value 1']\n",
    "for ii in range(total_response-1):\n",
    "    res += dataset['Value '+str(ii+2)]\n",
    "res /= total_response\n",
    "\n",
    "dataset['score'] = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "766402b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Response 1</th>\n",
       "      <th>Response 2</th>\n",
       "      <th>Value 1</th>\n",
       "      <th>Value 2</th>\n",
       "      <th>Value 3</th>\n",
       "      <th>Value 4</th>\n",
       "      <th>Value 5</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Obtain a trauma series of xrays followed by a ...</td>\n",
       "      <td>Perform primary trauma survey with attention t...</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Primary, secondary survey, X-ray of RLE to eva...</td>\n",
       "      <td>splint the leg and transfer them to a level 1 ...</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Immediate transfer to trauma center. Consider ...</td>\n",
       "      <td>Stabilize and transfer</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1. Check VS and perform a primary survey, obta...</td>\n",
       "      <td>Primary Survey, follow ATLS, CXR/PXR w/ RLE im...</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Transfer emergently to a Level 1 or 2 trauma c...</td>\n",
       "      <td>I would obtain an anticoagulation history, ass...</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Response 1  \\\n",
       "0  Obtain a trauma series of xrays followed by a ...   \n",
       "1  Primary, secondary survey, X-ray of RLE to eva...   \n",
       "2  Immediate transfer to trauma center. Consider ...   \n",
       "3  1. Check VS and perform a primary survey, obta...   \n",
       "4  Transfer emergently to a Level 1 or 2 trauma c...   \n",
       "\n",
       "                                          Response 2  Value 1  Value 2  \\\n",
       "0  Perform primary trauma survey with attention t...       10        1   \n",
       "1  splint the leg and transfer them to a level 1 ...       12        2   \n",
       "2                             Stabilize and transfer       13        2   \n",
       "3  Primary Survey, follow ATLS, CXR/PXR w/ RLE im...       12        1   \n",
       "4  I would obtain an anticoagulation history, ass...       11        2   \n",
       "\n",
       "   Value 3  Value 4  Value 5  score  \n",
       "0        2        2        3    2.0  \n",
       "1        3        2        3    2.4  \n",
       "2        3        3        2    2.6  \n",
       "3        3        4        2    2.4  \n",
       "4        3        2        1    2.2  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93841597",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dataset = load_dataset(\"sentence-transformers/stsb\", split=\"train\")\\n#dataset = load_dataset(\"tabilab/biosses\", split=\"train\")\\nprint(f\"Loaded {len(dataset)} examples. Sample:\")\\nprint(dataset[0], \"\\n\")'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dataset\n",
    "'''dataset = load_dataset(\"sentence-transformers/stsb\", split=\"train\")\n",
    "#dataset = load_dataset(\"tabilab/biosses\", split=\"train\")\n",
    "print(f\"Loaded {len(dataset)} examples. Sample:\")\n",
    "print(dataset[0], \"\\n\")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0750870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing dimension  768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jd/.cache/huggingface/modules/transformers_modules/nomic-ai/nomic-bert-2048/7710840340a098cfb869c4f65e87cf2b1b70caca/modeling_hf_nomic_bert.py:1634: UserWarning: Install Nomic's megablocks fork for better speed: `pip install git+https://github.com/nomic-ai/megablocks.git`\n",
      "  warnings.warn(\"Install Nomic's megablocks fork for better speed: \" +\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting embedding and measuring similarity ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 244/244 [05:37<00:00,  1.38s/it]\n"
     ]
    }
   ],
   "source": [
    "# Generate embeddings for the first few sentence pairs (do not run without need, save results, costs money)\n",
    "model_name = 'nomic-embed-text-v2-moe'#'nomic-embed-text-v1.5'\n",
    "dims = [768]#[64, 256, 512, 768]\n",
    "\n",
    "for dim in dims:\n",
    "    print('Doing dimension ', dim)\n",
    "    file_to_save = 'trauma/nomic_text-'+model_name+'_'+str(dim)+'_non_expert.pickle'\n",
    "    embeddings = pd.DataFrame()\n",
    "    sentence1 = []\n",
    "    sentence2 = []\n",
    "    embedding1 = []\n",
    "    embedding2 = []\n",
    "    cosine_similarity = []\n",
    "    human_score = []\n",
    "\n",
    "    model = SentenceTransformer(\"nomic-ai/\"+model_name, trust_remote_code=True, truncate_dim=64)\n",
    "\n",
    "    print('Extracting embedding and measuring similarity ...')\n",
    "    time.sleep(1)\n",
    "    for idx in tqdm(range(len(dataset))):\n",
    "        first_sentence = dataset[\"Response 1\"][idx]\n",
    "        emb1 = response = list(model.encode(first_sentence))\n",
    "        sentence1.append(\n",
    "            first_sentence\n",
    "        )\n",
    "        embedding1.append(\n",
    "            emb1\n",
    "        )\n",
    "        #############################\n",
    "        second_sentence = dataset[\"Response 2\"][idx]\n",
    "        emb2 = list(model.encode(second_sentence))\n",
    "        sentence2.append(\n",
    "            second_sentence\n",
    "        )\n",
    "        embedding2.append(\n",
    "            emb2\n",
    "        )\n",
    "        \n",
    "        ############################\n",
    "        cosine_similarity.append(\n",
    "            1 - cosine(emb1, emb2)\n",
    "        )\n",
    "        human_score.append(\n",
    "            dataset[\"score\"][idx]/5.0#/4.0 #comment out this depending on the data\n",
    "        )\n",
    "        \n",
    "        time.sleep(1)  # respect rate limits!\n",
    "\n",
    "    embeddings['Sentence 1'] = sentence1\n",
    "    embeddings['Sentence 2'] = sentence2\n",
    "    embeddings['Embedding of Sentence 1'] = embedding1\n",
    "    embeddings['Embedding of Sentence 2'] = embedding2\n",
    "    embeddings['Cosine similarity'] = cosine_similarity\n",
    "    embeddings['Human score'] = human_score\n",
    "\n",
    "    with open(file_to_save, 'wb') as f:\n",
    "        pickle.dump(embeddings, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "660b6c03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence 1</th>\n",
       "      <th>Sentence 2</th>\n",
       "      <th>Embedding of Sentence 1</th>\n",
       "      <th>Embedding of Sentence 2</th>\n",
       "      <th>Cosine similarity</th>\n",
       "      <th>Human score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Obtain a trauma series of xrays followed by a ...</td>\n",
       "      <td>Perform primary trauma survey with attention t...</td>\n",
       "      <td>[0.059141543, 0.08435341, 0.010328197, 0.03660...</td>\n",
       "      <td>[0.057072867, 0.015171323, -0.03103643, 0.0183...</td>\n",
       "      <td>0.596082</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Primary, secondary survey, X-ray of RLE to eva...</td>\n",
       "      <td>splint the leg and transfer them to a level 1 ...</td>\n",
       "      <td>[0.06695909, 0.01634268, -0.015910948, -0.0177...</td>\n",
       "      <td>[0.058899127, -0.005753417, -0.022170316, 0.04...</td>\n",
       "      <td>0.454241</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Immediate transfer to trauma center. Consider ...</td>\n",
       "      <td>Stabilize and transfer</td>\n",
       "      <td>[0.077441424, -0.00037554657, 0.011272862, -0....</td>\n",
       "      <td>[0.06735218, -0.03721028, -0.012768223, 0.0368...</td>\n",
       "      <td>0.343843</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1. Check VS and perform a primary survey, obta...</td>\n",
       "      <td>Primary Survey, follow ATLS, CXR/PXR w/ RLE im...</td>\n",
       "      <td>[0.04914354, 0.015866382, -0.003212126, 0.0296...</td>\n",
       "      <td>[0.057035383, 0.0021539722, -0.039034132, 0.04...</td>\n",
       "      <td>0.471331</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Transfer emergently to a Level 1 or 2 trauma c...</td>\n",
       "      <td>I would obtain an anticoagulation history, ass...</td>\n",
       "      <td>[0.06815589, -0.001376202, 0.014968201, -0.009...</td>\n",
       "      <td>[-0.012010266, -0.014603571, 0.010407524, 0.04...</td>\n",
       "      <td>0.550699</td>\n",
       "      <td>0.44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Sentence 1  \\\n",
       "0  Obtain a trauma series of xrays followed by a ...   \n",
       "1  Primary, secondary survey, X-ray of RLE to eva...   \n",
       "2  Immediate transfer to trauma center. Consider ...   \n",
       "3  1. Check VS and perform a primary survey, obta...   \n",
       "4  Transfer emergently to a Level 1 or 2 trauma c...   \n",
       "\n",
       "                                          Sentence 2  \\\n",
       "0  Perform primary trauma survey with attention t...   \n",
       "1  splint the leg and transfer them to a level 1 ...   \n",
       "2                             Stabilize and transfer   \n",
       "3  Primary Survey, follow ATLS, CXR/PXR w/ RLE im...   \n",
       "4  I would obtain an anticoagulation history, ass...   \n",
       "\n",
       "                             Embedding of Sentence 1  \\\n",
       "0  [0.059141543, 0.08435341, 0.010328197, 0.03660...   \n",
       "1  [0.06695909, 0.01634268, -0.015910948, -0.0177...   \n",
       "2  [0.077441424, -0.00037554657, 0.011272862, -0....   \n",
       "3  [0.04914354, 0.015866382, -0.003212126, 0.0296...   \n",
       "4  [0.06815589, -0.001376202, 0.014968201, -0.009...   \n",
       "\n",
       "                             Embedding of Sentence 2  Cosine similarity  \\\n",
       "0  [0.057072867, 0.015171323, -0.03103643, 0.0183...           0.596082   \n",
       "1  [0.058899127, -0.005753417, -0.022170316, 0.04...           0.454241   \n",
       "2  [0.06735218, -0.03721028, -0.012768223, 0.0368...           0.343843   \n",
       "3  [0.057035383, 0.0021539722, -0.039034132, 0.04...           0.471331   \n",
       "4  [-0.012010266, -0.014603571, 0.010407524, 0.04...           0.550699   \n",
       "\n",
       "   Human score  \n",
       "0         0.40  \n",
       "1         0.48  \n",
       "2         0.52  \n",
       "3         0.48  \n",
       "4         0.44  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05eda8a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
